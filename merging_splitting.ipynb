{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import spacy"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Printing tokens of a text\r\n",
    "text=\"John Wick is a 2014 American action thriller film directed by Chad Stahelski\"\r\n",
    "doc=nlp(text)\r\n",
    "for token in doc:\r\n",
    "  print(token.text)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "John\n",
      "Wick\n",
      "is\n",
      "a\n",
      "2014\n",
      "American\n",
      "action\n",
      "thriller\n",
      "film\n",
      "directed\n",
      "by\n",
      "Chad\n",
      "Stahelski\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Printing tokens after merging\r\n",
    "for token in doc:\r\n",
    "  print(token.text,token.pos_)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "John PROPN\n",
      "Wick PROPN\n",
      "is AUX\n",
      "a DET\n",
      "2014 NUM\n",
      "American ADJ\n",
      "action NOUN\n",
      "thriller NOUN\n",
      "film NOUN\n",
      "directed VERB\n",
      "by ADP\n",
      "Chad PROPN\n",
      "Stahelski PROPN\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "What if you want to store the versions ‘7T’ and ‘5T’ as seperate tokens. How can you split the tokens ?\r\n",
    "\r\n",
    "spaCy provides retokenzer.split() method to serve this purpose.\r\n",
    "\r\n",
    "The input parameters are :\r\n",
    "\r\n",
    "    token : The token of the doc which has to be split\r\n",
    "    orths : A list of texts, matching the original token. This is to tell the retokinzer how to split the token\r\n",
    "    heads : List of token or (token, subtoken) tuples specifying the tokens to attach the newly split subtokens to.\r\n",
    "    attrs : You can pass a dictionary to set attributes on all split tokens. Attribute names mapped to list of per-token attribute values.\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Splitting tokens using retokenizer.split()\r\n",
    "doc=nlp('I purchased the trendy OnePlus7 ')\r\n",
    "with doc.retokenize() as retokenizer:\r\n",
    "    heads = [(doc[3], 1), doc[2]]\r\n",
    "    retokenizer.split(doc[4], [\"OnePlus\", \"7\"],heads=heads)\r\n",
    "\r\n",
    "for token in doc:\r\n",
    "  print(token.text)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "I\n",
      "purchased\n",
      "the\n",
      "trendy\n",
      "OnePlus\n",
      "7\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('spacy': venv)"
  },
  "interpreter": {
   "hash": "da7a3f20bd736895ed2701e5b4df063f6abe2bef9c68d91259d0aafe078167d8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}